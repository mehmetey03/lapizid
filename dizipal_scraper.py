#!/usr/bin/env python3
"""
DÄ°ZÄ°PAL SCRAPER - Selenium ile JavaScript DesteÄŸi
"""

import requests
import re
import time
import json
import os
from datetime import datetime
from urllib.parse import urljoin, quote
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager

class DizipalScraper:
    def __init__(self, use_selenium=True):
        """Scraper baÅŸlatÄ±cÄ±
        
        Args:
            use_selenium (bool): JavaScript iÃ§erik iÃ§in Selenium kullan
        """
        print("ğŸš€ Dizipal Scraper baÅŸlatÄ±lÄ±yor...")
        self.use_selenium = use_selenium
        
        # Domain'i al
        self.base_url = self.get_current_domain()
        print(f"ğŸ”— Domain: {self.base_url}")
        print(f"ğŸ”„ Selenium KullanÄ±mÄ±: {'EVET' if use_selenium else 'HAYIR'}")
        
        # Selenium driver'Ä± baÅŸlat
        self.driver = None
        if use_selenium:
            self.init_selenium()
        
        # Normal requests session
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'tr-TR,tr;q=0.9,en-US;q=0.8,en;q=0.7',
        })
        
        # GitHub Actions iÃ§in optimize
        self.is_github_actions = os.getenv('GITHUB_ACTIONS') == 'true'
        
        # Kategoriler (GitHub Actions iÃ§in sÄ±nÄ±rlÄ±)
        if self.is_github_actions:
            print("âš¡ GitHub Actions modu: SÄ±nÄ±rlÄ± kategori")
            self.categories = {
                'aksiyon': 'aksiyon',
                'komedi': 'komedi'
            }
            self.years = [2024]
        else:
            self.categories = {
                'aksiyon': 'aksiyon',
                'komedi': 'komedi',
                'dram': 'dram',
                'korku': 'korku'
            }
            self.years = [2024, 2023]

    def init_selenium(self):
        """Selenium driver'Ä±nÄ± baÅŸlat"""
        try:
            print("ğŸŒ Selenium driver baÅŸlatÄ±lÄ±yor...")
            chrome_options = Options()
            
            # Headless mod (sunucu iÃ§in)
            chrome_options.add_argument('--headless')
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--window-size=1920,1080')
            
            # Cloudflare bypass iÃ§in
            chrome_options.add_argument('--disable-blink-features=AutomationControlled')
            chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
            chrome_options.add_experimental_option('useAutomationExtension', False)
            
            # WebDriverManager ile otomatik driver yÃ¼kleme
            service = Service(ChromeDriverManager().install())
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
            
            # Bot tespitini Ã¶nle
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            
            print("âœ… Selenium driver baÅŸlatÄ±ldÄ±")
            
        except Exception as e:
            print(f"âŒ Selenium baÅŸlatma hatasÄ±: {e}")
            print("âš ï¸ Selenium olmadan devam ediliyor...")
            self.use_selenium = False

    def get_current_domain(self):
        """GÃ¼ncel domain'i al"""
        try:
            url = "https://raw.githubusercontent.com/koprulu555/domain-kontrol2/refs/heads/main/dizipaldomain.txt"
            response = requests.get(url, timeout=10)
            for line in response.text.split('\n'):
                if line.startswith('guncel_domain='):
                    domain = line.split('=', 1)[1].strip()
                    if domain:
                        return domain.rstrip('/')
        except Exception as e:
            print(f"âš ï¸ Domain alÄ±namadÄ±: {e}")
        
        return "https://dizipal1223.com"

    def get_page_with_selenium(self, url):
        """Selenium ile sayfa iÃ§eriÄŸini al"""
        if not self.driver:
            return None
        
        try:
            print(f"ğŸŒ Selenium ile aÃ§Ä±lÄ±yor: {url}")
            self.driver.get(url)
            
            # SayfanÄ±n yÃ¼klenmesini bekle
            time.sleep(3)
            
            # JavaScript'in tamamlanmasÄ±nÄ± bekle
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            
            # Sayfa kaynaÄŸÄ±nÄ± al
            page_source = self.driver.page_source
            return page_source
            
        except Exception as e:
            print(f"âŒ Selenium hatasÄ±: {e}")
            return None

    def scrape_with_selenium(self, url):
        """Selenium ile film linklerini scrape et"""
        print(f"\nğŸ” Selenium ile taranÄ±yor: {url}")
        
        page_source = self.get_page_with_selenium(url)
        if not page_source:
            return []
        
        soup = BeautifulSoup(page_source, 'html.parser')
        
        # Film linklerini bul - Ã§eÅŸitli seÃ§iciler deneyelim
        film_links = []
        
        # 1. TÃ¼m olasÄ± film linklerini bul
        selectors = [
            'a[href*="/film/"]',
            '[data-url*="/film/"]',
            '[href*="/izle/"]',
            '.film-list a',
            '.movie-list a',
            '.poster a'
        ]
        
        for selector in selectors:
            elements = soup.select(selector)
            for elem in elements:
                href = elem.get('href') or elem.get('data-url')
                if href:
                    full_url = urljoin(self.base_url, href)
                    if '/film/' in full_url and full_url not in film_links:
                        film_links.append(full_url)
        
        # Benzersiz linkler
        unique_links = list(set(film_links))
        print(f"âœ… {len(unique_links)} film linki bulundu")
        
        return unique_links[:10] if self.is_github_actions else unique_links[:20]

    def get_film_info(self, film_url):
        """Film bilgilerini al"""
        try:
            print(f"ğŸ¥ Film bilgisi: {film_url}")
            
            # Selenium kullanarak film sayfasÄ±nÄ± aÃ§
            if self.use_selenium and self.driver:
                page_source = self.get_page_with_selenium(film_url)
                if not page_source:
                    return None
                soup = BeautifulSoup(page_source, 'html.parser')
            else:
                response = self.session.get(film_url, timeout=20)
                if response.status_code != 200:
                    return None
                soup = BeautifulSoup(response.content, 'html.parser')
            
            # Film baÅŸlÄ±ÄŸÄ±
            film_title = "Bilinmeyen Film"
            title_tag = soup.find('title')
            if title_tag:
                title_text = title_tag.text
                if 'izle' in title_text.lower():
                    parts = title_text.lower().split('izle')
                    film_title = parts[0].strip().title()
                elif ' | ' in title_text:
                    film_title = title_text.split(' | ')[0].strip()
                else:
                    film_title = title_text.strip()
            
            # H1'den kontrol et
            if film_title == "Bilinmeyen Film":
                h1_tag = soup.find('h1')
                if h1_tag:
                    film_title = h1_tag.text.strip()
            
            # Logo
            logo = ""
            meta_image = soup.find('meta', property='og:image')
            if meta_image:
                logo = meta_image.get('content', '')
            
            # YÄ±l
            year = "2024"
            year_match = re.search(r'(\d{4})', film_url)
            if year_match:
                year = year_match.group(1)
            
            # tvg-id
            clean_title = re.sub(r'[^\w\s-]', '', film_title.lower())
            clean_title = re.sub(r'\s+', '_', clean_title)
            tvg_id = f"{clean_title}_{year}"
            
            return {
                'url': film_url,
                'title': f"{film_title} ({year})",
                'tvg_id': tvg_id,
                'logo': logo,
                'year': year
            }
            
        except Exception as e:
            print(f"âŒ Film bilgisi hatasÄ±: {e}")
            return None

    def scrape_category(self, category_name, category_slug):
        """Bir kategoriyi scrape et"""
        print(f"\nğŸ¬ Kategori: {category_name.upper()}")
        
        category_films = []
        
        for year in self.years:
            print(f"   ğŸ“… {year} yÄ±lÄ±")
            
            # URL oluÅŸtur
            url = f"{self.base_url}/tur/{category_slug}?yil={year}"
            
            # Selenium ile film linklerini al
            film_links = self.scrape_with_selenium(url)
            
            if not film_links:
                print(f"   âš ï¸  Film bulunamadÄ±")
                continue
            
            # Film bilgilerini al
            for i, film_url in enumerate(film_links):
                if self.is_github_actions and i >= 3:  # GitHub iÃ§in sÄ±nÄ±rlÄ±
                    break
                
                film_info = self.get_film_info(film_url)
                if film_info:
                    film_info['group_title'] = f"Film - {category_name.upper()}"
                    category_films.append(film_info)
                    print(f"      âœ… {film_info['title']}")
                
                time.sleep(1)  # Sunucu yÃ¼kÃ¼nÃ¼ azalt
            
            if self.is_github_actions and len(category_films) >= 3:
                break
        
        print(f"   ğŸ“Š Toplam: {len(category_films)} film")
        return category_films

    def generate_m3u(self, films, filename='dizipal_filmler.m3u'):
        """M3U dosyasÄ± oluÅŸtur"""
        print(f"\nğŸ“ M3U oluÅŸturuluyor: {filename}")
        
        # EÄŸer film yoksa test M3U oluÅŸtur
        if not films:
            print("âš ï¸  Film bulunamadÄ±, test M3U oluÅŸturuluyor...")
            films = [{
                'url': self.base_url,
                'title': 'Dizipal Filmleri',
                'tvg_id': 'dizipal_main',
                'logo': '',
                'group_title': 'Film - TEST',
                'year': '2024'
            }]
        
        # M3U baÅŸlÄ±ÄŸÄ±
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        m3u_lines = [
            '#EXTM3U',
            f'# Dizipal Filmleri',
            f'# OluÅŸturulma: {timestamp}',
            f'# Toplam: {len(films)} film',
            f'# URL: {self.base_url}',
            '#'
        ]
        
        # Filmleri ekle
        for film in films:
            m3u_lines.append(f'#EXTINF:-1 tvg-id="{film["tvg_id"]}" tvg-logo="{film["logo"]}" group-title="{film["group_title"]}", {film["title"]}')
            m3u_lines.append(film['url'])
        
        # Dosyaya yaz
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write('\n'.join(m3u_lines))
            
            print(f"âœ… {filename} oluÅŸturuldu")
            print(f"ğŸ“ Boyut: {len('\\n'.join(m3u_lines))} karakter")
            
            # Ä°lk 5 satÄ±rÄ± gÃ¶ster
            print(f"\nğŸ“‹ Ä°lk 5 satÄ±r:")
            lines = '\n'.join(m3u_lines).split('\n')
            for i in range(min(5, len(lines))):
                print(f"  {i+1}. {lines[i][:80]}{'...' if len(lines[i]) > 80 else ''}")
            
            return True
            
        except Exception as e:
            print(f"âŒ M3U yazma hatasÄ±: {e}")
            return False

    def run(self):
        """Ana Ã§alÄ±ÅŸtÄ±rma"""
        print("=" * 60)
        print("ğŸš€ DÄ°ZÄ°PAL M3U SCRAPER - SELENIUM")
        print("=" * 60)
        
        all_films = []
        total_categories = len(self.categories)
        
        for i, (category_name, category_slug) in enumerate(self.categories.items(), 1):
            print(f"\n[{i}/{total_categories}] ", end="")
            films = self.scrape_category(category_name, category_slug)
            all_films.extend(films)
            
            if i < total_categories:
                time.sleep(2)
        
        # M3U oluÅŸtur
        self.generate_m3u(all_films)
        
        print("\n" + "=" * 60)
        print(f"âœ… TAMAMLANDI!")
        print(f"ğŸ“Š Toplam film: {len(all_films)}")
        
        if all_films:
            print(f"\nğŸ¬ BULUNAN FÄ°LMLER:")
            for i, film in enumerate(all_films[:10], 1):
                print(f"  {i}. {film['title']}")
            if len(all_films) > 10:
                print(f"  ... ve {len(all_films) - 10} film daha")
        
        print("=" * 60)
        
        # Selenium'u kapat
        if self.driver:
            self.driver.quit()
            print("ğŸŒ Selenium kapatÄ±ldÄ±")
        
        return len(all_films)

def main():
    """Ana fonksiyon"""
    try:
        # GitHub Actions iÃ§in Selenium kullan
        use_selenium = True
        
        scraper = DizipalScraper(use_selenium=use_selenium)
        film_count = scraper.run()
        
        # En az 1 film yoksa test M3U oluÅŸtur
        if film_count == 0:
            print("\nâš ï¸ Film bulunamadÄ±, test M3U oluÅŸturuluyor...")
            with open('dizipal_filmler.m3u', 'w', encoding='utf-8') as f:
                f.write('#EXTM3U\n#EXTINF:-1,Dizipal Test\nhttps://dizipal1223.com\n')
        
        # BaÅŸarÄ±lÄ± Ã§Ä±k
        exit(0)
        
    except Exception as e:
        print(f"\nâŒ KRÄ°TÄ°K HATA: {e}")
        import traceback
        traceback.print_exc()
        
        # Hata durumunda test M3U
        try:
            with open('dizipal_filmler.m3u', 'w', encoding='utf-8') as f:
                f.write(f'#EXTM3U\n# Hata: {str(e)[:100]}\n')
        except:
            pass
        
        exit(1)

if __name__ == "__main__":
    main()
